/**
 * User SolarFlux default aggregate publish settings.
 */
CREATE TABLE solaruser.user_flux_default_agg_pub_settings (
	user_id			BIGINT NOT NULL,
	created			TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
	modified		TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
	publish			BOOLEAN NOT NULL DEFAULT FALSE,
	retain			BOOLEAN NOT NULL DEFAULT FALSE,
	CONSTRAINT user_flux_default_agg_pub_settings_pk PRIMARY KEY (user_id),
	CONSTRAINT user_flux_default_agg_pub_settings_user_fk FOREIGN KEY (user_id)
		REFERENCES solaruser.user_user (id) MATCH SIMPLE
		ON UPDATE NO ACTION ON DELETE CASCADE
);

/**
 * User SolarFlux aggregate publish settings.
 */
CREATE TABLE solaruser.user_flux_agg_pub_settings (
	user_id			BIGINT NOT NULL,
	id				BIGINT GENERATED BY DEFAULT AS IDENTITY NOT NULL,
	created			TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
	modified		TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
	node_ids		BIGINT[],
	source_ids		CHARACTER VARYING(64)[],
	publish			BOOLEAN NOT NULL DEFAULT TRUE,
	retain			BOOLEAN NOT NULL DEFAULT FALSE,
	CONSTRAINT user_flux_agg_pub_settings_pk PRIMARY KEY (user_id, id),
	CONSTRAINT user_flux_agg_pub_settings_user_fk FOREIGN KEY (user_id)
		REFERENCES solaruser.user_user (id) MATCH SIMPLE
		ON UPDATE NO ACTION ON DELETE CASCADE
);

CREATE INDEX user_flux_agg_pub_settings_node_idx ON solaruser.user_flux_agg_pub_settings
USING GIN (node_ids, source_ids);

/**
 * Type to represent the SolarFlux publish settings for a datum stream.
 */
CREATE TYPE solardatm.flux_pub_settings AS (
	node_id 	BIGINT,
	source_id 	CHARACTER VARYING(64),
	publish 	BOOLEAN,
	retain 		BOOLEAN
);

/**
 * Resolve SolarFlux publish settings for a user node and source.
 *
 * @param userid the ID of the user
 * @param node the ID of the node
 * @param source the ID of the source
 */
CREATE OR REPLACE FUNCTION solaruser.flux_agg_pub_settings(
		userid		BIGINT,
		node 		BIGINT,
		source 		CHARACTER VARYING(64)
	)
	RETURNS SETOF solardatm.flux_pub_settings
	LANGUAGE SQL STABLE STRICT ROWS 1 AS
$$
WITH matches AS (
	SELECT -1 AS weight
		, 0 AS id
		, def.publish
		, def.retain
	FROM solaruser.user_flux_default_agg_pub_settings def
	WHERE def.user_id = userid

	UNION ALL

	SELECT CASE
			WHEN fap.node_ids IS NULL OR fap.source_ids IS NULL THEN 0
			ELSE 1
		  END AS weight
		, fap.id
		, fap.publish
		, fap.retain
	FROM solaruser.user_node un
	INNER JOIN solaruser.user_flux_agg_pub_settings fap ON un.user_id = fap.user_id
	WHERE un.user_id = userid
		AND un.node_id = node
		AND (fap.node_ids IS NULL OR fap.node_ids @> ARRAY[node])
		AND (fap.source_ids IS NULL OR fap.source_ids @> ARRAY[source])
)
SELECT node
	, source
	, COALESCE(solarcommon.first(publish ORDER BY weight DESC, id DESC), FALSE) AS publish
	, COALESCE(solarcommon.first(retain ORDER BY weight DESC, id DESC), FALSE) AS retain
FROM matches
$$;


/**
 * Resolve SolarFlux publish settings for a user node and source.
 *
 * @param node the ID of the node
 * @param source the ID of the source
 */
CREATE OR REPLACE FUNCTION solardatm.flux_agg_pub_settings(
		node 		BIGINT,
		source 		CHARACTER VARYING(64)
	)
	RETURNS SETOF solardatm.flux_pub_settings
	LANGUAGE SQL STABLE STRICT ROWS 1 AS
$$
WITH usernode AS (
	SELECT user_id, node_id
	FROM solaruser.user_node
	WHERE node_id = node
)
SELECT s.*
FROM usernode, solaruser.flux_agg_pub_settings(usernode.user_id, usernode.node_id, source) AS s
$$;


CREATE OR REPLACE FUNCTION solardatm.process_one_agg_stale_datm(kind CHARACTER)
	RETURNS SETOF solardatm.obj_datm_id LANGUAGE plpgsql VOLATILE AS
$$
DECLARE
	agg_span 				INTERVAL;
	dest_name				TEXT;

	curs 					CURSOR FOR
							SELECT * FROM solardatm.agg_stale_datm
							WHERE agg_kind = kind LIMIT 1 FOR UPDATE SKIP LOCKED;
	stale 					solardatm.agg_stale_datm;
	meta					record;
	tz						TEXT;

	local_ts_start			TIMESTAMP;
	local_ts_end			TIMESTAMP;
	ts_end					TIMESTAMP WITH TIME ZONE;
	ts_prevstart			TIMESTAMP WITH TIME ZONE;

	num_rows				BIGINT;

	result_row				solardatm.obj_datm_id;
	flux_pub 				solardatm.flux_pub_settings;
BEGIN
	CASE kind
		WHEN 'd' THEN
			agg_span := interval '1 day';
			dest_name := 'agg_datm_daily';
		WHEN 'M' THEN
			agg_span := interval '1 month';
			dest_name := 'agg_datm_monthly';
		ELSE
			agg_span := interval '1 hour';
			dest_name := 'agg_datm_hourly';
	END CASE;

	OPEN curs;
	FETCH NEXT FROM curs INTO stale;

	IF FOUND THEN
		-- get stream metadata & time zone; will determine if node or location stream
		SELECT * FROM solardatm.find_metadata_for_stream(stale.stream_id) INTO meta;
		tz := COALESCE(meta.time_zone, 'UTC');
		result_row := (stale.stream_id, stale.ts_start, stale.agg_kind, meta.obj_id, meta.source_id, meta.kind);

		-- stash local start/end dates to work with calendar intervals
		-- the ts_prevstart is used to deal with tz changes with streams
		local_ts_start := stale.ts_start AT TIME ZONE tz;
		local_ts_end   := local_ts_start + agg_span;
		ts_end         := local_ts_end AT TIME ZONE tz;
		ts_prevstart   := (local_ts_start - agg_span) AT TIME ZONE tz;

		BEGIN
			IF kind = 'h' THEN
				EXECUTE format(
						'INSERT INTO solardatm.%I (stream_id, ts_start, data_i, data_a, data_s, data_t, stat_i, read_a) '
						'SELECT stream_id, ts_start, data_i, data_a, data_s, data_t, stat_i, read_a '
						'FROM solardatm.rollup_datm_for_time_span($1, $2, $3) '
						'ON CONFLICT (stream_id, ts_start) DO UPDATE SET '
						'    data_i = EXCLUDED.data_i, '
						'    data_a = EXCLUDED.data_a, '
						'    data_s = EXCLUDED.data_s, '
						'    data_t = EXCLUDED.data_t, '
						'    stat_i = EXCLUDED.stat_i, '
						'    read_a = EXCLUDED.read_a'
						, dest_name)
				USING stale.stream_id, stale.ts_start, ts_end;
			ELSE
				EXECUTE format(
						'INSERT INTO solardatm.%I (stream_id, ts_start, data_i, data_a, data_s, data_t, stat_i, read_a) '
						'SELECT stream_id, ts_start, data_i, data_a, data_s, data_t, stat_i, read_a '
						'FROM solardatm.rollup_agg_data_for_time_span($1, $2, $3, $4) '
						'ON CONFLICT (stream_id, ts_start) DO UPDATE SET '
						'    data_i = EXCLUDED.data_i,'
						'    data_a = EXCLUDED.data_a,'
						'    data_s = EXCLUDED.data_s,'
						'    data_t = EXCLUDED.data_t,'
						'    stat_i = EXCLUDED.stat_i,'
						'    read_a = EXCLUDED.read_a'
						, dest_name)
				USING stale.stream_id, stale.ts_start, ts_end, CASE kind WHEN 'M' THEN 'd' ELSE 'h' END;
			END IF;
			GET DIAGNOSTICS num_rows = ROW_COUNT;
		EXCEPTION WHEN invalid_text_representation THEN
			RAISE EXCEPTION 'Invalid text representation processing stream % aggregate % range % - %',
				stale.stream_id, kind, stale.ts_start, ts_end
			USING ERRCODE = 'invalid_text_representation',
				SCHEMA = 'solardatm',
				TABLE = dest_name,
				HINT = 'Check the solardatm.rollup_datm_for_time_span()/da_datum or solardatm.rollup_agg_data_for_time_span()/solardatm.find_agg_datm_for_time_span() with matching stream/date range parameters.';
		END;

		IF num_rows < 1 THEN
			-- delete everything within time span, using >ts_prevstart to handle tz changes
			EXECUTE format(
					'DELETE FROM solardatm.%I '
					'WHERE stream_id = $1 AND ts_start > $2 AND ts_start < $3'
					, dest_name)
			USING stale.stream_id, ts_prevstart, ts_end;
		ELSEIF kind <> 'h' THEN
			-- delete everything but inserted row, using >ts_prevstart to handle tz changes
			EXECUTE format(
					'DELETE FROM solardatm.%I '
					'WHERE stream_id = $1 AND ts_start > $2 AND ts_start < $3 '
					'    AND ts_start <> $4'
					, dest_name)
			USING stale.stream_id, ts_prevstart, ts_end, stale.ts_start;
		END IF;

		-- now make sure we recalculate the next aggregate level by submitting a stale record
		-- for the next level; also update daily audit stats
		CASE kind
			WHEN 'h' THEN
				INSERT INTO solardatm.agg_stale_datm (stream_id, ts_start, agg_kind)
				VALUES (stale.stream_id, date_trunc('day', local_ts_start) AT TIME ZONE tz, 'd')
				ON CONFLICT DO NOTHING;

			WHEN 'd' THEN
				INSERT INTO solardatm.agg_stale_datm (stream_id, ts_start, agg_kind)
				VALUES (stale.stream_id, date_trunc('month', local_ts_start) AT TIME ZONE tz, 'M')
				ON CONFLICT DO NOTHING;

				-- handle update to raw audit data
				INSERT INTO solardatm.aud_stale_datm (stream_id, ts_start, aud_kind)
				VALUES (stale.stream_id, date_trunc('day', local_ts_start) AT TIME ZONE tz, '0')
				ON CONFLICT DO NOTHING;

				-- handle update to hourly audit data
				INSERT INTO solardatm.aud_stale_datm (stream_id, ts_start, aud_kind)
				VALUES (stale.stream_id, date_trunc('day', local_ts_start) AT TIME ZONE tz, 'h')
				ON CONFLICT DO NOTHING;

				-- handle update to daily audit data
				INSERT INTO solardatm.aud_stale_datm (stream_id, ts_start, aud_kind)
				VALUES (stale.stream_id, date_trunc('day', local_ts_start) AT TIME ZONE tz, 'd')
				ON CONFLICT DO NOTHING;
			ELSE
				-- handle update to monthly audit data
				INSERT INTO solardatm.aud_stale_datm (stream_id, ts_start, aud_kind)
				VALUES (stale.stream_id, date_trunc('month', local_ts_start) AT TIME ZONE tz, 'M')
				ON CONFLICT DO NOTHING;
		END CASE;

		-- mark flux stale if node datum and processed record is for the "current" time
		-- TODO: consider publishing location datum as well; would require support in SolarJobs
		IF meta.kind = 'n' AND local_ts_start = date_trunc(
							CASE kind WHEN 'h' THEN 'hour' WHEN 'd' THEN 'day' ELSE 'month' END
							, CURRENT_TIMESTAMP AT TIME ZONE tz) THEN
			SELECT * FROM solardatm.flux_agg_pub_settings(result_row.obj_id, result_row.source_id) INTO flux_pub;
			IF FOUND AND flux_pub.publish THEN
				INSERT INTO solardatm.agg_stale_flux (stream_id, agg_kind)
				VALUES (stale.stream_id, kind)
				ON CONFLICT (stream_id, agg_kind) DO NOTHING;
			END IF;
		END IF;

		DELETE FROM solardatm.agg_stale_datm WHERE CURRENT OF curs;

		RETURN NEXT result_row;
	END IF;

	CLOSE curs;
END;
$$;
